{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMaWv5RiWUL+iKwRDc9Bo4M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Crawling Website PTA Trunojoyo"],"metadata":{"id":"XOInFae6pDbb"}},{"cell_type":"markdown","source":["## Install Library BeautifulSoup"],"metadata":{"id":"TLMQMrLcpIvN"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vUrJstPpntCB","executionInfo":{"status":"ok","timestamp":1692942854579,"user_tz":-420,"elapsed":4867,"user":{"displayName":"20-126 Ahmad Rosyihuddin","userId":"03632124637273514654"}},"outputId":"bc6ae363-9e3f-4d4b-e271-71dba4d06e2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n"]}],"source":["!pip install beautifulsoup4"]},{"cell_type":"markdown","source":["## Import Library"],"metadata":{"id":"WT-DFQLdpNtd"}},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","import requests\n","import csv"],"metadata":{"id":"Jd6R87A3pRB7","executionInfo":{"status":"ok","timestamp":1692942855152,"user_tz":-420,"elapsed":586,"user":{"displayName":"20-126 Ahmad Rosyihuddin","userId":"03632124637273514654"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Create Crawling Function"],"metadata":{"id":"gsY5TcSrpSu8"}},{"cell_type":"code","source":["def get_data(url):\n","  data_page = []\n","  response = requests.get(url)\n","  if response.status_code == 200:\n","    page = BeautifulSoup(response.content)\n","    container_content = page.find('li', {\"data-id\" : \"id-1\"})\n","    header_page = container_content.find('div', {\"style\" : \"float:left; width:540px;\"})\n","\n","    #  Mengambil judul TA\n","    get_title = header_page.find('a', class_ = 'title').text.strip().split('\\r\\n')\n","    title = \" \".join(get_title)\n","    data_page.append(title)\n","\n","    # Mengambil Penulis dan juga Dospem\n","    creator = header_page.find_all('span')\n","    for i in creator:\n","      splitting_text = i.text.strip().split(':')\n","      if splitting_text[0].strip() == 'Penulis':\n","        data_page.append(splitting_text[1].strip())\n","      elif splitting_text[0].strip() == 'Dosen Pembimbing I':\n","        data_page.append(splitting_text[1].strip())\n","      else:\n","        data_page.append(splitting_text[1].strip())\n","\n","    # Mengambil Abstrak\n","    get_abstrak = container_content.find('p', {\"align\" : \"justify\"}).text.strip().split('\\r\\n')\n","    abstrak = \" \".join(get_abstrak)\n","    data_page.append(abstrak)\n","\n","  return data_page\n","\n","\n","def crawling_pta(url):\n","  hasil_crawling = []\n","  response = requests.get(url)\n","  if response.status_code == 200:\n","    page = BeautifulSoup(response.content)\n","    container_content = page.find('ul', class_= 'items')\n","    list_content = container_content.find_all('li')\n","\n","    for content in list_content:\n","      view_button = content.find('a', class_ = 'gray button').get('href')\n","      hasil_crawling.append(get_data(view_button))\n","\n","    next_page = page.find_all('a', class_='pag_button')\n","    for i in next_page:\n","      if i.text.strip() == '>':\n","        return (hasil_crawling, i.get('href'))\n","\n","def main(url, num_page):\n","  content, next_page = crawling_pta(url)\n","\n","  for i in range(num_page-1):\n","    more_content, next_page = crawling_pta(next_page)\n","    content += more_content\n","\n","  with open('crawling_pta.csv', mode='w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerow(['Judul', 'Penulis', 'Dosen Pembimbing I', 'Dosen Pembimbing II', 'Abstrak'])\n","    writer.writerows(content)\n","\n","  print(f'Data Berhasil Di Simpan Kedalam File crawling_pta.csv Dengan Jumlah : {len(content)} Data')\n","\n","main('https://pta.trunojoyo.ac.id/c_search/byprod/10', 4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KayoLXa_n14_","executionInfo":{"status":"ok","timestamp":1692942893117,"user_tz":-420,"elapsed":37970,"user":{"displayName":"20-126 Ahmad Rosyihuddin","userId":"03632124637273514654"}},"outputId":"f15c1e9e-ddbf-4cb2-86bf-2c7e801c813c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Data Berhasil Di Simpan Kedalam File crawling_pta.csv Dengan Jumlah : 20 Data\n"]}]}]}